{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_from_Web_Scraped_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EM-PYi0Mknwy"
      },
      "outputs": [],
      "source": [
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "options = webdriver.ChromeOptions()"
      ],
      "metadata": {
        "id": "co6M0309kqyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "metadata": {
        "id": "Gl1d4Jt-k8Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver = webdriver.Chrome(options=options)"
      ],
      "metadata": {
        "id": "v9xdpppDlCmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "driver.maximize_window()"
      ],
      "metadata": {
        "id": "gFooEBRklJaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By"
      ],
      "metadata": {
        "id": "SyRVzpbolPhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reading Link File"
      ],
      "metadata": {
        "id": "a0qCGGhtl8m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links = pd.read_excel('Input.xlsx')\n",
        "links.head()"
      ],
      "metadata": {
        "id": "qg7Eeqg6lbrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for  index,row in links.head(2).iterrows():\n",
        "  print(row['URL_ID'],row['URL'])"
      ],
      "metadata": {
        "id": "4nwaIz1-l3Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now we will scrape data from the data given in these links"
      ],
      "metadata": {
        "id": "SkCDctK2mEDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to scrape data from the links\n",
        "def scrape_data(link):\n",
        "  global driver\n",
        "  driver.get(link)\n",
        "  title=driver.find_element(By.XPATH,\"//div[contains(@class,'td-post-content')]\")\n",
        "  driver.implicitly_wait(10)\n",
        "  return title.text"
      ],
      "metadata": {
        "id": "UWBFLGA1l57h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to save the scraped files\n",
        "def save_file(scrapdata):\n",
        "  for data in scrapdata:\n",
        "    fname=str(data['URL-ID'])+\".txt\"\n",
        "    f=open(\"./sample_data/scraped_files/\"+fname,'w+',encoding='utf-8')\n",
        "    f.write(data['TEXT'])\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "fnfifYHXnTG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perfroming Scraping operation"
      ],
      "metadata": {
        "id": "UBfFRj7Gp-LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data=[]\n",
        "for index,row in links.iterrows():\n",
        "  item={}\n",
        "  item['URL-ID']=row['URL_ID']\n",
        "  item['TEXT']=scrape_data(row['URL'])\n",
        "  data.append(item)\n",
        "save_file(data)\n",
        "       "
      ],
      "metadata": {
        "id": "D4zPkTRvp31U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making a data frame of scrapped data"
      ],
      "metadata": {
        "id": "xewuKqYUqrjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "7fdKYWtT4_JE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "8S4Ic7oc5BeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all data in one csv file\n",
        "df.to_csv('contect.csv',index=None)"
      ],
      "metadata": {
        "id": "pckcF-SDrEAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### let us do some pre processing of the data before we perform sentiment  analysis on it"
      ],
      "metadata": {
        "id": "58l9FJ-2uDV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Number of sentences\"]=df['TEXT'].apply(lambda x:len(x.split('.')))"
      ],
      "metadata": {
        "id": "yt0VKMAvrdf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "oEyLfIgIusn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replacing short form of words"
      ],
      "metadata": {
        "id": "bqgBlc3Muzbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def short_forms():    \n",
        "    return {\n",
        "        \"cant\":\"can not\",\n",
        "        \"dont\":\"do not\",\n",
        "        \"wont\":\"will not\",\n",
        "        \"ain't\":\"is not\",\n",
        "        \"amn't\":\"am not\",\n",
        "        \"aren't\":\"are not\",\n",
        "        \"can't\":\"cannot\",\n",
        "        \"'cause\":\"because\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"couldn't've\":\"could not have\",\n",
        "        \"could've\":\"could have\",\n",
        "        \"daren't\":\"dare not\",\n",
        "        \"daresn't\":\"dare not\",\n",
        "        \"dasn't\":\"dare not\",\n",
        "        \"didn't\":\"did not\",\n",
        "        \"doesn't\":\"does not\",\n",
        "        \"don't\":\"do not\",\n",
        "        \"e'er\":\"ever\",\n",
        "        \"em\":\"them\",\n",
        "        \"everyone's\":\"everyone is\",\n",
        "        \"finna\":\"fixing to\",\n",
        "        \"gimme\":\"give me\",\n",
        "        \"gonna\":\"going to\",\n",
        "        \"gon't\":\"go not\",\n",
        "        \"gotta\":\"got to\",\n",
        "        \"hadn't\":\"had not\",\n",
        "        \"hasn't\":\"has not\",\n",
        "        \"haven't\":\"have not\",\n",
        "        \"he'd\":\"he would\",\n",
        "        \"he'll\":\"he will\",\n",
        "        \"he's\":\"he is\",\n",
        "        \"he've\":\"he have\",\n",
        "        \"how'd\":\"how would\",\n",
        "        \"how'll\":\"how will\",\n",
        "        \"how're\":\"how are\",\n",
        "        \"how's\":\"how is\",\n",
        "        \"I'd\":\"I would\",\n",
        "        \"I'll\":\"I will\",\n",
        "        \"I'm\":\"I am\",\n",
        "        \"I'm'a\":\"I am about to\",\n",
        "        \"I'm'o\":\"I am going to\",\n",
        "        \"isn't\":\"is not\",\n",
        "        \"it'd\":\"it would\",\n",
        "        \"it'll\":\"it will\",\n",
        "        \"it's\":\"it is\",\n",
        "        \"I've\":\"I have\",\n",
        "        \"kinda\":\"kind of\",\n",
        "        \"let's\":\"let us\",\n",
        "        \"mayn't\":\"may not\",\n",
        "        \"may've\":\"may have\",\n",
        "        \"mightn't\":\"might not\",\n",
        "        \"might've\":\"might have\",\n",
        "        \"mustn't\":\"must not\",\n",
        "        \"mustn't've\":\"must not have\",\n",
        "        \"must've\":\"must have\",\n",
        "        \"needn't\":\"need not\",\n",
        "        \"ne'er\":\"never\",\n",
        "        \"o'\":\"of\",\n",
        "        \"o'er\":\"over\",\n",
        "        \"ol'\":\"old\",\n",
        "        \"oughtn't\":\"ought not\",\n",
        "        \"shalln't\":\"shall not\",\n",
        "        \"shan't\":\"shall not\",\n",
        "        \"she'd\":\"she would\",\n",
        "        \"she'll\":\"she will\",\n",
        "        \"she's\":\"she is\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"shouldn't've\":\"should not have\",\n",
        "        \"should've\":\"should have\",\n",
        "        \"somebody's\":\"somebody is\",\n",
        "        \"someone's\":\"someone is\",\n",
        "        \"something's\":\"something is\",\n",
        "        \"that'd\":\"that would\",\n",
        "        \"that'll\":\"that will\",\n",
        "        \"that're\":\"that are\",\n",
        "        \"that's\":\"that is\",\n",
        "        \"there'd\":\"there would\",\n",
        "        \"there'll\":\"there will\",\n",
        "        \"there're\":\"there are\",\n",
        "        \"there's\":\"there is\",\n",
        "        \"these're\":\"these are\",\n",
        "        \"they'd\":\"they would\",\n",
        "        \"they'll\":\"they will\",\n",
        "        \"they're\":\"they are\",\n",
        "        \"they've\":\"they have\",\n",
        "        \"this's\":\"this is\",\n",
        "        \"those're\":\"those are\",\n",
        "        \"'tis\":\"it is\",\n",
        "        \"'twas\":\"it was\",\n",
        "        \"wanna\":\"want to\",\n",
        "        \"wasn't\":\"was not\",\n",
        "        \"we'd\":\"we would\",\n",
        "        \"we'd've\":\"we would have\",\n",
        "        \"we'll\":\"we will\",\n",
        "        \"we're\":\"we are\",\n",
        "        \"weren't\":\"were not\",\n",
        "        \"we've\":\"we have\",\n",
        "        \"what'd\":\"what did\",\n",
        "        \"what'll\":\"what will\",\n",
        "        \"what're\":\"what are\",\n",
        "        \"what's\":\"what is\",\n",
        "        \"what've\":\"what have\",\n",
        "        \"when's\":\"when is\",\n",
        "        \"where'd\":\"where did\",\n",
        "        \"where're\":\"where are\",\n",
        "        \"where's\":\"where is\",\n",
        "        \"where've\":\"where have\",\n",
        "        \"which's\":\"which is\",\n",
        "        \"who'd\":\"who would\",\n",
        "        \"who'd've\":\"who would have\",\n",
        "        \"who'll\":\"who will\",\n",
        "        \"who're\":\"who are\",\n",
        "        \"who's\":\"who is\",\n",
        "        \"who've\":\"who have\",\n",
        "        \"why'd\":\"why did\",\n",
        "        \"why're\":\"why are\",\n",
        "        \"why's\":\"why is\",\n",
        "        \"won't\":\"will not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"would've\":\"would have\",\n",
        "        \"y'all\":\"you all\",\n",
        "        \"you'd\":\"you would\",\n",
        "        \"you'll\":\"you will\",\n",
        "        \"you're\":\"you are\",\n",
        "        \"you've\":\"you have\",\n",
        "        \"Whatcha\":\"What are you\",\n",
        "        \"luv\":\"love\",\n",
        "        \"sux\":\"sucks\",\n",
        "        \"couldn't\":\"could not\",\n",
        "        \"wouldn't\":\"would not\",\n",
        "        \"shouldn't\":\"should not\",\n",
        "        \"im\":\"i am\"\n",
        "        }"
      ],
      "metadata": {
        "id": "z_6exbrGuuOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re  ##check if a particular string matches a given regular expression\n",
        "import string\n",
        "\n",
        "## funtion to replace the short forms \n",
        "def normalization(data):\n",
        "    data = str(data).lower()\n",
        "    # URL\n",
        "    data = re.sub('((www.[^\\s]+)|(https?://[^\\s]+))',' ',data)\n",
        "    data = re.sub(r'#([^\\s]+)', r'\\1', data)\n",
        "\n",
        "    # Number\n",
        "    data = ''.join([i for i in data if not i.isdigit()])\n",
        "\n",
        "    # Punctuation\n",
        "\n",
        "    for sym in string.punctuation:\n",
        "        data = data.replace(sym, \" \")\n",
        "    short_form = short_forms()\n",
        "    data = data.replace(\"’\",\"'\")\n",
        "    words = data.split()\n",
        "    converted = [short_form[word] if word in short_form else word for word in words]\n",
        "    data = \" \".join(converted)\n",
        "    return data"
      ],
      "metadata": {
        "id": "YTGdn22yvH7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TEXT']=df['TEXT'].apply(normalization)"
      ],
      "metadata": {
        "id": "Q6_e6Hppyry3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['TEXT']=df['TEXT'].apply(lambda x:x.lower())"
      ],
      "metadata": {
        "id": "5XlNTd40y4hK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "GiQtudAszDEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing Sentiment Analysis"
      ],
      "metadata": {
        "id": "D4SGF3rBAPSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LoughranMcDonald_MasterDictionary_2020 is a dictionary which contains the \n",
        "#sentiment analysis words which will act as a reference for our data set words\n",
        "\n",
        "guide=pd.read_csv('LoughranMcDonald_MasterDictionary_2020.csv')\n",
        "guide.head()"
      ],
      "metadata": {
        "id": "cSEebDD7ACjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "guide[guide['Negative']>0]['Word']"
      ],
      "metadata": {
        "id": "SAKLVzvaFzW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Assigning Positive and Negative score to our words based on the dictionary words"
      ],
      "metadata": {
        "id": "R1392rs_BK5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos = [] \n",
        "neg =[]\n",
        "Uncertain = []\n",
        "for index,row in guide.iterrows():\n",
        "    if row['Negative']>0:\n",
        "        neg.append(row['Word'].lower())\n",
        "    elif row['Positive']>0:\n",
        "        pos.append(row['Word'].lower())\n",
        "    elif row['Uncertainty']>0:\n",
        "        Uncertain.append(row['Word'].lower())"
      ],
      "metadata": {
        "id": "qtLOjyz5BBRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wbvo4WV_Ck5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def positivescore(text):\n",
        "  score=0\n",
        "  global pos\n",
        "  words=text.split()\n",
        "  for word in words:\n",
        "    if word in pos:\n",
        "      score+=1\n",
        "  return score"
      ],
      "metadata": {
        "id": "MeAsMkaQCl5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def negativescore(text):\n",
        "  score=0\n",
        "  global neg\n",
        "  words=text.split()\n",
        "  for word in words:\n",
        "    if word in neg:\n",
        "      score -= 1\n",
        "  return score"
      ],
      "metadata": {
        "id": "nbHAeiQ4C-Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['PositiveScore']=df['TEXT'].apply(positivescore)\n",
        "df['NegativeScore']=df['TEXT'].apply(negativescore)"
      ],
      "metadata": {
        "id": "kja5R6LJDTjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting all the different parameters"
      ],
      "metadata": {
        "id": "sP-7U-yRD9-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['POLARITY SCORE']=(df['PositiveScore']-df['NegativeScore'])/ ((df['PositiveScore'] + df['NegativeScore']) + 0.000001)\n",
        "df['WORD COUNT']=df['TEXT'].apply(lambda x:len(x.split()))\n",
        "df['SUBJECTIVITY SCORE']=(df['PositiveScore'] + df['NegativeScore'])/ ((df['WORD COUNT']) + 0.000001)\n",
        "df['AVG SENTENCE LENGTH']=df['WORD COUNT']/df['Number of sentences']\n",
        "df['AVG NUMBER OF WORDS PER SENTENCE'] = df['WORD COUNT']/df['Number of sentences']"
      ],
      "metadata": {
        "id": "XbWt_VxnDowl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## for avg length of words\n",
        "def avgwordlength(text):\n",
        "    words = text.split()\n",
        "    no_of_words=len(words)\n",
        "    total_char=0\n",
        "    for word in words:\n",
        "        total_char+=len(word)\n",
        "    return total_char/no_of_words"
      ],
      "metadata": {
        "id": "GR1JNQRiDp2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## for seeing if the sentence has pronoun\n",
        "def pronoun(text):\n",
        "    pronouns = r\"(\\b(s?i|me|we|my|ours|us|I|Me|We|My|Ours|Us)\\b)\"\n",
        "    result = 0\n",
        "\n",
        "    matches = re.finditer(pronouns,text,re.MULTILINE)\n",
        "    for nummatch,match in enumerate(matches):\n",
        "        result+=1\n",
        "    return result"
      ],
      "metadata": {
        "id": "x-FMyek0E0oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AVG WORD LENGTH']=df['TEXT'].apply(avgwordlength)\n",
        "df['AVG SENTENCE LENGTH']=df['WORD COUNT']/df['Number of sentences']\n",
        "df['PERSONAL PRONOUNS']=df['TEXT'].apply(pronoun)"
      ],
      "metadata": {
        "id": "XxsYbWjeE3P0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e3f8mSpAG_X6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['PositiveScore']>0]"
      ],
      "metadata": {
        "id": "ifL5zsaIFCjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['URL']=links['URL']"
      ],
      "metadata": {
        "id": "8QSYRHLgHAT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "rIV9DugVHoBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}